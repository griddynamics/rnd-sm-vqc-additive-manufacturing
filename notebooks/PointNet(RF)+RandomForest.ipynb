{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Yz84lGSvtc0N"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
            "[Open3D INFO] WebRTC GUI backend enabled.\n",
            "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "import open3d as o3d\n",
        "from joblib import load, dump\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.special import softmax\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import scipy.spatial.distance\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from torch import nn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "random.seed = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_YZd9Ybvtp6z"
      },
      "outputs": [],
      "source": [
        "rf_point = load(\"./model_weights/rf_point.joblib\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RtwE7AVQtvHb"
      },
      "source": [
        "# PointNet model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2HHwAK_ctwlI"
      },
      "outputs": [],
      "source": [
        "# Used for extracting feature rich vector giving a 1 dimensional vector for point net\n",
        "\n",
        "class Tnet(nn.Module):\n",
        "   def __init__(self, k=3):\n",
        "      super().__init__()\n",
        "      self.k=k\n",
        "      self.conv1 = nn.Conv1d(k,64,1)\n",
        "      self.conv2 = nn.Conv1d(64,128,1)\n",
        "      self.conv3 = nn.Conv1d(128,1024,1)\n",
        "      self.fc1 = nn.Linear(1024,512)\n",
        "      self.fc2 = nn.Linear(512,256)\n",
        "      self.fc3 = nn.Linear(256,k*k)\n",
        "\n",
        "      self.bn1 = nn.BatchNorm1d(64)\n",
        "      self.bn2 = nn.BatchNorm1d(128)\n",
        "      self.bn3 = nn.BatchNorm1d(1024)\n",
        "      self.bn4 = nn.BatchNorm1d(512)\n",
        "      self.bn5 = nn.BatchNorm1d(256)\n",
        "       \n",
        "\n",
        "   def forward(self, input):\n",
        "      # input.shape == (bs,n,3)\n",
        "      bs = input.size(0)\n",
        "      xb = F.relu(self.bn1(self.conv1(input)))\n",
        "      xb = F.relu(self.bn2(self.conv2(xb)))\n",
        "      xb = F.relu(self.bn3(self.conv3(xb)))\n",
        "      pool = nn.MaxPool1d(xb.size(-1))(xb)\n",
        "      flat = nn.Flatten(1)(pool)\n",
        "      xb = F.relu(self.bn4(self.fc1(flat)))\n",
        "      xb = F.relu(self.bn5(self.fc2(xb)))\n",
        "      \n",
        "      #initialize as identity\n",
        "      init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
        "      if xb.is_cuda:\n",
        "        init=init.cuda()\n",
        "      matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
        "      return matrix\n",
        "\n",
        "# Used for position estimation and point estimation using global and\n",
        "# local coordinates\n",
        "class Transform(nn.Module):\n",
        "   def __init__(self):\n",
        "        super().__init__()\n",
        "        self.input_transform = Tnet(k=3)\n",
        "        self.feature_transform = Tnet(k=64)\n",
        "        self.conv1 = nn.Conv1d(3,64,1)#(3,64,1)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(64,128,1)\n",
        "        self.conv3 = nn.Conv1d(128,1024,1)\n",
        "       \n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\n",
        "       \n",
        "   def forward(self, input):\n",
        "        matrix3x3 = self.input_transform(input)\n",
        "        # batch matrix multiplication\n",
        "        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n",
        "\n",
        "        xb = F.relu(self.bn1(self.conv1(xb)))\n",
        "\n",
        "        matrix64x64 = self.feature_transform(xb)\n",
        "        xb = torch.bmm(torch.transpose(xb,1,2), matrix64x64).transpose(1,2)\n",
        "\n",
        "        xb = F.relu(self.bn2(self.conv2(xb)))\n",
        "        xb = self.bn3(self.conv3(xb))\n",
        "        xb = nn.MaxPool1d(xb.size(-1))(xb)\n",
        "        output = nn.Flatten(1)(xb)\n",
        "        return output, matrix3x3, matrix64x64\n",
        "\n",
        "class PointNet(nn.Module):\n",
        "    def __init__(self, classes = 2):\n",
        "        super().__init__()\n",
        "        self.transform = Transform()\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, classes)\n",
        "        \n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        xb, matrix3x3, matrix64x64 = self.transform(input)\n",
        "        xb1 = F.relu(self.bn1(self.fc1(xb)))\n",
        "        xb2 = F.relu(self.bn2(self.dropout(self.fc2(xb1))))\n",
        "        output = self.fc3(xb2)\n",
        "        return self.logsoftmax(output), matrix3x3, matrix64x64, xb1, xb2 \n",
        "\n",
        "# PointNet custom loss calculating with all 3 model outputs\n",
        "\n",
        "# LOSS\n",
        "def pointnetloss(outputs, labels, m3x3, m64x64, alpha = 0.0001):\n",
        "    criterion = torch.nn.NLLLoss()\n",
        "    bs = outputs.size(0)\n",
        "    id3x3 = torch.eye(3, requires_grad=True).repeat(bs, 1, 1)\n",
        "    id64x64 = torch.eye(64, requires_grad=True).repeat(bs, 1, 1)\n",
        "    if outputs.is_cuda:\n",
        "        id3x3 = id3x3.cuda()\n",
        "        id64x64 = id64x64.cuda()\n",
        "    diff3x3 = id3x3 - torch.bmm(m3x3, m3x3.transpose(1, 2))\n",
        "    diff64x64 = id64x64 - torch.bmm(m64x64, m64x64.transpose(1, 2))\n",
        "    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3) + torch.norm(diff64x64)) / float(bs)\n",
        "\n",
        "# Normalization used as a preprocessing step\n",
        "class Normalize(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "        \n",
        "        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0) \n",
        "        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
        "\n",
        "        return  norm_pointcloud\n",
        "\n",
        "def default_transforms():\n",
        "    return transforms.Compose([\n",
        "                                Normalize(),\n",
        "                                \n",
        "                              ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XMXKS3GWt9Fa"
      },
      "outputs": [],
      "source": [
        "class PointCloudDataRFSampler(Dataset):\n",
        "    def __init__(self, dataframe_path, sample_rate=1024, transform=default_transforms()):\n",
        "        self.df = pd.read_csv(dataframe_path)\n",
        "        self.classes = {\"anomaly\": 1, \"normal\": 0}\n",
        "        self.sample_rate=sample_rate\n",
        "        self.transforms=transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "\n",
        "    def __preproc__(self, file):#, reference_path):\n",
        "        # Loads point cloud\n",
        "        resampled = pd.read_csv(file).values\n",
        "        # Apply transforms (only normalize but additional can be added)\n",
        "        if self.transforms:\n",
        "            pointcloud = self.transforms(resampled)\n",
        "        return torch.from_numpy(pointcloud)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pcd_path = self.df.iloc[idx]['sampled_pcds']\n",
        "        # ref_path = self.df.iloc[idx]['reference_path']\n",
        "        category = self.df.iloc[idx]['label']\n",
        "        pointcloud = self.__preproc__(pcd_path)#, ref_path)\n",
        "        return {'pointcloud': pointcloud, \n",
        "                'category': self.classes[category]}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OV7TUFUtuKN7",
        "outputId": "9634ba80-04dc-4b7d-f83f-fd71140495a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32\n",
            "8\n"
          ]
        }
      ],
      "source": [
        "train_point_ds = PointCloudDataRFSampler(\"./data/RF_sampled_df.csv\", sample_rate=1024)\n",
        "test_point_ds = PointCloudDataRFSampler(\"./data/RF_sampled_df_test.csv\", sample_rate=1024)\n",
        "\n",
        "print(len(train_point_ds))\n",
        "print(len(test_point_ds))\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset=train_point_ds, batch_size=32)\n",
        "test_loader = DataLoader(dataset=test_point_ds, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iawq5vyduMqn",
        "outputId": "9aaa2942-306f-4d86-e0b5-53aaaa1ba3fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "learning_rate = 0.0001\n",
        "sample_rate = 1024\n",
        "epochs = 10\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "pointnet = PointNet()\n",
        "pointnet.to(device)\n",
        "optimizer = torch.optim.Adam(pointnet.parameters(), lr=learning_rate)\n",
        "\n",
        "pointnet.load_state_dict(torch.load(\"./model_weights/PointNet_RF_samples_0.pth\")) # Load best fitting model\n",
        "pointnet.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-ih-EP3XuOHp"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Calculate embeddings for use in random forest mesh classifier\n",
        "rf_train_level_1_embs = []\n",
        "rf_train_level_2_embs = []\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(train_loader):\n",
        "        print('Batch [%4d / %4d]' % (i+1, len(train_loader)))\n",
        "                   \n",
        "        pcd = data['pointcloud'].to(device).float()\n",
        "        labels = data['category'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        _, _, _, emb1, emb2 = pointnet(pcd.transpose(1,2))\n",
        "        rf_train_level_1_embs += list(emb1.cpu().numpy())\n",
        "        rf_train_level_2_embs += list(emb2.cpu().numpy())\n",
        "\n",
        "\n",
        "rf_test_level_1_embs = []\n",
        "rf_test_level_2_embs = []\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_loader):\n",
        "        print('Batch [%4d / %4d]' % (i+1, len(test_loader)))\n",
        "        \n",
        "        pcd = data['pointcloud'].to(device).float()\n",
        "        labels = data['category'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        _, _, _, emb1, emb2 = pointnet(pcd.transpose(1,2))\n",
        "        # _, preds = torch.max(outputs.data, 1)\n",
        "        rf_test_level_1_embs += list(emb1.cpu().numpy())\n",
        "        rf_test_level_2_embs += list(emb2.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QED1W5wBv0hD"
      },
      "outputs": [],
      "source": [
        "# Load aggregated percentile data\n",
        "train_anomaly_mesh = pd.read_csv(\"./data/aggregated_train.csv\")\n",
        "test_anomaly_mesh = pd.read_csv(\"./data/aggregated_test.csv\")\n",
        "\n",
        "# Take embeddings from PointNet of shape 512 (lvl1) and 256 (lvl2)\n",
        "# Concatenate embedding and percentile vectors\n",
        "rf_full_test_dataset = []\n",
        "for aggr_file, np_emb in zip(test_anomaly_mesh.iterrows(), rf_test_level_1_embs):\n",
        "  rf_full_test_dataset.append(np.concatenate([aggr_file[1].drop([\"label_obj_is_anom\"]).values, np_emb]))\n",
        "\n",
        "rf_full_test_dataset_lvl2 = []\n",
        "for aggr_file, np_emb in zip(test_anomaly_mesh.iterrows(), rf_test_level_2_embs):\n",
        "  rf_full_test_dataset_lvl2.append(np.concatenate([aggr_file[1].drop([\"label_obj_is_anom\"]).values, np_emb]))\n",
        "\n",
        "rf_full_train_dataset = []\n",
        "for aggr_file, np_emb in zip(train_anomaly_mesh.iterrows(), rf_train_level_1_embs):\n",
        "  rf_full_train_dataset.append(np.concatenate([aggr_file[1].drop([\"label_obj_is_anom\"]).values, np_emb]))\n",
        "\n",
        "rf_full_train_dataset_lvl2 = []\n",
        "for aggr_file, np_emb in zip(train_anomaly_mesh.iterrows(), rf_train_level_2_embs):\n",
        "  rf_full_train_dataset_lvl2.append(np.concatenate([aggr_file[1].drop([\"label_obj_is_anom\"]).values, np_emb]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"./data/train_df.csv\")\n",
        "test_df = pd.read_csv(\"./data/test_df.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KWtpsPWvroD",
        "outputId": "76919cc3-dd51-4a4d-b988-b427627dc052"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[3 1]\n",
            " [3 1]]\n"
          ]
        }
      ],
      "source": [
        "#Train Random Forest model on embeddings \n",
        "rf_sample_features = np.array(rf_full_train_dataset)\n",
        "rf_labels = np.array([1 if val == \"anomaly\" else 0 for val in train_df['label']])\n",
        "rf_mesh_rf_sample = RandomForestClassifier()\n",
        "rf_mesh_rf_sample.fit(rf_sample_features, rf_labels)\n",
        "\n",
        "test_rf_sample_features = np.array(rf_full_test_dataset)\n",
        "test_rf_labels = np.array([1 if val == \"anomaly\" else 0 for val in test_df['label']])\n",
        "\n",
        "test_preds = rf_mesh_rf_sample.predict(test_rf_sample_features)\n",
        "cm = confusion_matrix(test_rf_labels, test_preds);\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea16-FSex2EZ",
        "outputId": "3cb16688-4ca4-4826-c33b-b87cb06ee12c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 3]\n",
            " [1 3]]\n"
          ]
        }
      ],
      "source": [
        "# Level2 embedding random forest\n",
        "rf_sample_features_lvl2 = np.array(rf_full_train_dataset_lvl2)\n",
        "rf_labels = np.array([1 if val == \"anomaly\" else 0 for val in train_df['label']])\n",
        "\n",
        "rf_mesh_rf_sample_lvl2 = RandomForestClassifier()\n",
        "rf_mesh_rf_sample_lvl2.fit(rf_sample_features_lvl2, rf_labels)\n",
        "\n",
        "test_rf_labels_lvl2 = np.array([1 if val == \"anomaly\" else 0 for val in test_df['label']])\n",
        "\n",
        "test_rf_sample_features_lvl2 = np.array(rf_full_test_dataset_lvl2)\n",
        "\n",
        "test_preds_lvl2 = rf_mesh_rf_sample_lvl2.predict(test_rf_sample_features_lvl2)\n",
        "cm = confusion_matrix(test_rf_labels_lvl2, test_preds_lvl2);\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5yV-OwWuiyI",
        "outputId": "df2da36f-fcfd-477d-a61b-0e4edde8d6c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[3 1]\n",
            " [0 0]]\n",
            "[[1 3]\n",
            " [0 0]]\n"
          ]
        }
      ],
      "source": [
        "def get_inds(df_90_10, full_df):\n",
        "  inds = []\n",
        "  for idx, filename in enumerate(full_df[\"object_path\"]):\n",
        "    if filename in df_90_10[\"object_path\"].tolist():\n",
        "      inds.append(idx)\n",
        "  return inds\n",
        "\n",
        "# Get indices used of 90/10 indices and extract the points for the relevant indices\n",
        "test_anomaly_mesh_90_10 = test_anomaly_mesh.iloc[get_inds(pd.read_csv(\"./data/test_df_90_10.csv\"), test_df)]\n",
        "\n",
        "test_dataset_90_10_lvl1 = []\n",
        "test_dataset_90_10_lvl2 = []\n",
        "for i in range(test_anomaly_mesh_90_10.shape[0]):\n",
        "  idx = test_anomaly_mesh_90_10.index[i]\n",
        "  test_dataset_90_10_lvl1.append(np.concatenate([test_anomaly_mesh_90_10.iloc[i].drop([\"label_obj_is_anom\"]).values, \n",
        "                                                 rf_test_level_1_embs[idx]]))\n",
        "  test_dataset_90_10_lvl2.append(np.concatenate([test_anomaly_mesh_90_10.iloc[i].drop([\"label_obj_is_anom\"]).values, \n",
        "                                                 rf_test_level_2_embs[idx]]))\n",
        "\n",
        "test_labels_90_10 = test_anomaly_mesh_90_10[\"label_obj_is_anom\"].astype(int)\n",
        "test_dataset_90_10_lvl1 = np.array(test_dataset_90_10_lvl1)\n",
        "test_dataset_90_10_lvl2 = np.array(test_dataset_90_10_lvl2)\n",
        "\n",
        "preds_90_10 = rf_mesh_rf_sample.predict(test_dataset_90_10_lvl1)\n",
        "cm_90_10 = confusion_matrix(test_labels_90_10, preds_90_10);\n",
        "print(cm_90_10)  \n",
        "\n",
        "preds_lvl2_90_10 = rf_mesh_rf_sample_lvl2.predict(test_dataset_90_10_lvl2)\n",
        "cm_lvl2_90_10 = confusion_matrix(test_labels_90_10, preds_lvl2_90_10);\n",
        "print(cm_lvl2_90_10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "fS-KlGamuUOm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['./model_weights/rf_mesh+PointNet+RFSampling_emb_256m_50-50.joblib']"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save model and transfer to drive\n",
        "\n",
        "dump(rf_mesh_rf_sample, \"./model_weights/rf_mesh+PointNet+RFSampling_emb_512.joblib\")\n",
        "dump(rf_mesh_rf_sample_lvl2, \"./model_weights/rf_mesh+PointNet+RFSampling_emb_256m.joblib\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXof1Uke2emy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
